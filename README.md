Overview
This project presents a Mixed Reality (MR) environment designed to observe and analyze the behavior of humanoid robots in real-time. By integrating internal parameters computed by humanoids with the actual environment, we provide a unique platform for developers and researchers to visualize and debug autonomous behaviors effectively.

Key Features
Real-Time Data Streaming: Internal parameters are captured at each sampling time and stored in real-time on distributed log servers, allowing for continuous monitoring and analysis.
3D Graphical Representation: Multi-dimensional parameters are visually represented in 3D, enabling users to observe complex data relationships and behaviors.
Head-Mounted Display (HMD) Support: Users can view the mixed reality environment through a video feed via a head-mounted display, providing an immersive experience.
Arbitrary Viewpoints: Stored parameters can be projected onto the current scene from various perspectives, enhancing the understanding of the humanoid's interaction with its environment.
Behavior Debugging: The MR environment serves as a powerful tool for developers to review and debug the behaviors of humanoids against real-world scenarios.
Deep Learning Integration: The system incorporates concepts of deep learning, enabling humanoid robots to learn and improve their behaviors during training phases.
Implementation
This project features the full-size humanoid system implementation using the HRP-2 robot. Experimental examples demonstrate the capabilities of the MR environment and the effectiveness of real-time data visualization.

Requirements
Compatible head-mounted display (HMD)
Distributed log server setup
Software dependencies (details to be provided)
Installation
Clone the repository:
bash

Copy
git clone <repository-url>
cd <repository-directory>
Install required dependencies (details to be provided).
Set up the distributed log server and configure it according to the instructions provided in the documentation.
Launch the Mixed Reality application and connect your HMD.
Usage
Start the application to begin capturing internal parameters from the HRP-2 humanoid.
Use the HMD to navigate through the mixed reality environment and observe the graphical representations.
Experiment with different viewpoints to analyze the humanoid's behavior in relation to the actual environment.
Contributing
Contributions are welcome! Please submit issues or pull requests for any enhancements or bug fixes.

Acknowledgments
Special thanks to the development team and contributors who helped bring this project to fruition. Your efforts in advancing humanoid robotics and mixed reality technologies are greatly appreciated.
